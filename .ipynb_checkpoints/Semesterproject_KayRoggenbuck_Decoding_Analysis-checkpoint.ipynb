{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(y, evts_dict):\n",
    "    '''\n",
    "    converts the y values to class-values for the cases:\n",
    "    a) all faces = 1, all cars = 0\n",
    "    b) intact faces = 1, rest 0\n",
    "    c) intact car = 0, intact face = 1, scrambled cars = 2, scrambled faces = 3\n",
    "    '''\n",
    "    y_faces_cars = np.zeros(shape=(len(y)))\n",
    "    y_intact_faces_rest = np.zeros(shape=(len(y)))\n",
    "    y_four_classes = np.zeros(shape=(len(y)))\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        for key, value in evts_dict.items():\n",
    "            if value == y[i]:\n",
    "                event_id = int(key.split(':')[1])\n",
    "                # intact face\n",
    "                if event_id <= 40:\n",
    "                    y_faces_cars[i] = 1\n",
    "                    y_four_classes[i] = 1\n",
    "                    y_intact_faces_rest[i] = 1\n",
    "                #intact car\n",
    "                elif event_id <= 80:\n",
    "                    y_faces_cars[i] = 0\n",
    "                    y_four_classes[i] = 0\n",
    "                # scrambled face\n",
    "                elif event_id >= 101 and event_id <= 140:\n",
    "                    y_faces_cars[i] = 1\n",
    "                    y_four_classes[i] = 3\n",
    "                # scrambled car\n",
    "                elif event_id >= 141 and event_id <= 180:\n",
    "                    y_faces_cars[i] = 0\n",
    "                    y_four_classes[i] = 2\n",
    "    \n",
    "    return y_faces_cars, y_intact_faces_rest, y_four_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_baseline_mean(time_points, array):\n",
    "    '''\n",
    "    >>> calculate_baseline_mean([-3. -2, -1, 0, 1, 2, 3], [0,0,0,0,0,0,0])\n",
    "    0.0\n",
    "    \n",
    "    >>> calculate_baseline_mean([-3. -2, -1, 0, 1, 2, 3], [1,3,2,1,1,4,5])\n",
    "    200.0\n",
    "    '''\n",
    "    baseline_mean = 0\n",
    "    i = 0\n",
    "    while time_points[i] < 0:\n",
    "        baseline_mean += array[i]\n",
    "        i += 1\n",
    "    baseline_mean = (baseline_mean/i) * 100\n",
    "    return baseline_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_control_group(time_points, array):\n",
    "    '''\n",
    "    extract the control group as all points before the stimulus onset (time_points[i]<0)\n",
    "    '''\n",
    "    array = np.asarray(array)\n",
    "    basline_control = []\n",
    "    index = 0\n",
    "    while time_points[index] < 0:\n",
    "        basline_control.extend(array[:,index])\n",
    "        index += 1\n",
    "    return basline_control, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test(treatment, control, iterations):\n",
    "    '''\n",
    "    A simple implementation of a permutation test\n",
    "    '''\n",
    "    number_of_treatments = len(treatment)\n",
    "    number_of_control = len(control)\n",
    "    number_of_all_values = number_of_treatments + number_of_control\n",
    "    mean_tretment = np.average(treatment)\n",
    "    mean_control = np.average(control)\n",
    "    initial_statistic = mean_tretment - mean_control\n",
    "    \n",
    "    all_values = []\n",
    "    all_values.extend(control)\n",
    "    all_values.extend(treatment)\n",
    "    \n",
    "    statistic_values = []\n",
    "    counter = 1\n",
    "    for i in range(iterations):\n",
    "        # get a new random permutation of the groups\n",
    "        permutation = np.random.permutation(number_of_all_values)\n",
    "        # apply the permutation\n",
    "        new_control = [all_values[i] for i in permutation[0:number_of_control]]\n",
    "        new_treatment = [all_values[i] for i in permutation[number_of_control:]]\n",
    "        # calculate the statistic\n",
    "        new_statistic = np.mean(new_treatment) - np.mean(new_control)\n",
    "        statistic_values.append(new_statistic)\n",
    "        # a counter for the calculation of the p-value\n",
    "        if new_statistic >= initial_statistic:\n",
    "            counter += 1\n",
    "    \n",
    "    # calculate the p-value\n",
    "    p_value = counter / (iterations+1)\n",
    "    return (statistic_values,initial_statistic, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value_over_time(start_index, control_group, array, perm_test_iter):\n",
    "    '''\n",
    "    calculates p-values for each timepoint of the array with a permutation test.\n",
    "    Therefore a permutation test is used with the given control group \n",
    "    and one time group from each of the subjects as treatment.\n",
    "    '''\n",
    "    array = np.asarray(array)\n",
    "    j = start_index\n",
    "    p_value_list = []\n",
    "    while j < len(array[0]):\n",
    "        treatment = array[:,j]\n",
    "        value_list, initial_statistic, p = permutation_test(treatment,control_group, perm_test_iter)\n",
    "        p_value_list.append(p)\n",
    "        print((j-start_index)/(len(mean_over_splits[0]-start_index))*100)\n",
    "        j += 1\n",
    "    return p_value_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osfclient\n",
    "import mne\n",
    "import mne_bids\n",
    "import numpy as np\n",
    "import ccs_eeg_utils\n",
    "import ccs_eeg_semesterproject\n",
    "from mne_bids import (BIDSPath,read_raw_bids)\n",
    "from matplotlib import pyplot as plt\n",
    "from importlib import reload \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from helper_functions import *\n",
    "\n",
    "%matplotlib qt\n",
    "path = \"../local/bidsN170\"\n",
    "temp_path = \"/ses-N170/eeg/\"\n",
    "\n",
    "# INFO, WARNING\n",
    "mne.set_log_level(verbose='INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Decoding for all subjects (classify over time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Subject_ID', 'Amplitude', 'Stimulus', 'Condition']\n",
    "peak_data = []\n",
    "score_list_if_rest = []\n",
    "score_list_faces_cars = []\n",
    "for s in range(1,41):\n",
    "    if len(str(s)) > 1:\n",
    "        sub = '0' + str(s)\n",
    "    else:\n",
    "        sub = '00' + str(s)\n",
    "    # use the data without the channel positions to avoid a bug\n",
    "    read_path = path + \"/sub-\" + sub + temp_path + \"sub-\" + sub +\"_cleaned_no_channel_positions.fif\"\n",
    "    raw = mne.io.read_raw_fif(read_path)\n",
    "    \n",
    "    epochs, evts_dict = load_epochs(raw)\n",
    "    epochs.drop_bad()\n",
    "    \n",
    "    # data of the epochs\n",
    "    X = epochs.get_data() \n",
    "    # the classes (to predict/to calculate the accuracy)\n",
    "    y = epochs.events[:, 2]\n",
    "    y_faces_cars, y_intact_faces_rest, y_four_classes = get_classes(y, evts_dict)\n",
    "    \n",
    "    # defines the pipeline\n",
    "    pipe = make_pipeline(mne.decoding.Scaler(epochs.info),\n",
    "                    mne.decoding.Vectorizer(),\n",
    "                    LogisticRegression(solver='lbfgs'))\n",
    "    \n",
    "    timeDecode = mne.decoding.SlidingEstimator(pipe)\n",
    "\n",
    "    # the score for the intact faces/rest classes\n",
    "    # use a cross-validation with 10 splits to avoid overfitting\n",
    "    scores_if_rest = mne.decoding.cross_val_multiscore(timeDecode, X, y_intact_faces_rest, cv=10, n_jobs=4)\n",
    "    score_list_if_rest.append(scores_if_rest)\n",
    "    \n",
    "    # the score for the all faces/all cars classes\n",
    "    # use a cross-validation with 10 splits to avoid overfitting\n",
    "    scores_face_car = mne.decoding.cross_val_multiscore(timeDecode, X, y_faces_cars, cv=10, n_jobs=4)\n",
    "    score_list_faces_cars.append(scores_face_car)\n",
    "    \n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) if / rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array('decoding_data/time_score_intact_faces_rest_logreg.npy', score_list_if_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list_if_rest = load_array_from_memory('decoding_data/time_score_intact_faces_rest_logreg.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the timepoints\n",
    "number_of_datapoints = len(score_list_if_rest[0][0])\n",
    "x = get_timepoints(epoch_start=-0.1, epoch_end=1, number_of_datapoints=number_of_datapoints)\n",
    "\n",
    "\n",
    "mean_over_splits = [np.mean(score_list_if_rest[i], axis=0) for i in range(0,40)]\n",
    "mean_over_splits_and_subjects = np.mean(mean_over_splits, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean = calculate_baseline_mean(x, mean_over_splits_and_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "ax2 = figure.add_subplot(111)\n",
    "title = ''\n",
    "ax2.set_title('mean accuracy over splits and subjects for (intact faces/rest)')\n",
    "ax2.set_xlabel('time[ms]')\n",
    "ax2.set_ylabel('accuracy[%]')\n",
    "plt.axvline(x = 0, color = 'black') \n",
    "ax2.plot(x, mean_over_splits_and_subjects*100, label='mean accuracy')\n",
    "ax2.plot(x, np.ones(shape=(number_of_datapoints))*baseline_mean, color='black')\n",
    "ax2.legend(loc=1)\n",
    "#plt.savefig('./analysis_images/' + title)\n",
    "#plt.close(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basline_control, i = create_baseline_control_group(x, mean_over_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_over_time(i, basline_control, mean_over_splits, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "ax2 = figure.add_subplot(111)\n",
    "title = ''\n",
    "ax2.set_title('p-value  for different time points')\n",
    "ax2.set_xlabel('time[ms]')\n",
    "ax2.set_ylabel('p-value')\n",
    "ax2.plot(x[i:], p_value_list)\n",
    "#ax2.legend(loc=1)\n",
    "plt.yscale('log')\n",
    "#plt.savefig('./analysis_images/' + title)\n",
    "#plt.close(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array('decoding_data/p_values_if_rest.npy', p_value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_list = load_array_from_memory('decoding_data/p_values_if_rest.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) all faces / all cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array('decoding_data/time_score_all_faces_all_cars_logreg.npy', score_list_faces_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list_faces_cars = load_array_from_memory('decoding_data/time_score_all_faces_all_cars_logreg.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the timepoints\n",
    "number_of_datapoints = len(score_list_faces_cars[0][0])\n",
    "x = get_timepoints(epoch_start=-0.1, epoch_end=1, number_of_datapoints=number_of_datapoints)\n",
    "\n",
    "mean_over_splits = [np.mean(score_list_faces_cars[i], axis=0) for i in range(0,40)]\n",
    "mean_over_splits_and_subjects = np.mean(mean_over_splits, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean = calculate_baseline_mean(x, mean_over_splits_and_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "ax2 = figure.add_subplot(111)\n",
    "title = ''\n",
    "ax2.set_title('mean accuracy over splits and subjects for (all faces/all cars)')\n",
    "ax2.set_xlabel('time[ms]')\n",
    "ax2.set_ylabel('accuracy[%]')\n",
    "plt.axvline(x = 0, color = 'black') \n",
    "ax2.plot(x, mean_over_splits_and_subjects*100, label='mean accuracy')\n",
    "ax2.plot(x, np.ones(shape=(number_of_datapoints))*baseline_mean, color='black')\n",
    "ax2.legend(loc=1)\n",
    "#plt.savefig('./analysis_images/' + title)\n",
    "#plt.close(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cluster permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basline_control, i = create_baseline_control_group(x, mean_over_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_list = p_value_over_time(i, basline_control, mean_over_splits, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "ax2 = figure.add_subplot(111)\n",
    "title = ''\n",
    "ax2.set_title('p-value  for different time points')\n",
    "ax2.set_xlabel('time[ms]')\n",
    "ax2.set_ylabel('p-value')\n",
    "ax2.plot(x[i:], p_value_list)\n",
    "#ax2.legend(loc=1)\n",
    "plt.yscale('log')\n",
    "#plt.savefig('./analysis_images/' + title)\n",
    "#plt.close(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array('decoding_data/p_values_all_faces_all_cars.npy', p_value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_list = load_array_from_memory('decoding_data/p_values_all_faces_all_cars.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Decoding for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'P8'\n",
    "header = ['Subject_ID', 'Amplitude', 'Stimulus', 'Condition']\n",
    "peak_data = []\n",
    "eeg_crit = 100e-6\n",
    "score_list_if_rest = []\n",
    "score_list_faces_cars = []\n",
    "for s in range(1,41):\n",
    "    print('Subject '+ str(s) + '############################################')\n",
    "    if len(str(s)) > 1:\n",
    "        sub = '0' + str(s)\n",
    "    else:\n",
    "        sub = '00' + str(s)\n",
    "    # load the data without channel positions\n",
    "    read_path = path + \"/sub-\" + sub + temp_path + \"sub-\" + sub +\"_cleaned_no_channel_positions.fif\"\n",
    "    raw = mne.io.read_raw_fif(read_path)\n",
    "    \n",
    "    #epochs = peak_to_peak(raw, eeg_crit)\n",
    "    epochs, evts_dict = load_epochs(raw)\n",
    "    epochs.drop_bad()\n",
    "    \n",
    "    X = epochs.get_data()  # signals: n_epochs, n_meg_channels, n_times\n",
    "    y = epochs.events[:, 2]  # stimuli values\n",
    "    \n",
    "    y_faces_cars, y_intact_faces_rest, y_four_classes = get_classes(y, evts_dict)\n",
    "    \n",
    "    # defines the pipeline\n",
    "    clf = make_pipeline(mne.decoding.Scaler(epochs.info),\n",
    "                    mne.decoding.Vectorizer(),\n",
    "                    LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "    # Adding channel locations seem to destroy this function...\n",
    "    scores_if_rest = mne.decoding.cross_val_multiscore(clf, X, y_intact_faces_rest, cv=10, n_jobs=4)\n",
    "\n",
    "    # Mean scores across cross-validation splits\n",
    "    score = np.mean(scores_if_rest, axis=0)\n",
    "    score_list_if_rest.append(score*100)\n",
    "    \n",
    "    \n",
    "    # Adding channel locations seem to destroy this function...\n",
    "    scores_face_car = mne.decoding.cross_val_multiscore(clf, X, y_faces_cars, cv=10, n_jobs=4)\n",
    "\n",
    "    # Mean scores across cross-validation splits\n",
    "    score = np.mean(scores_face_car, axis=0)\n",
    "    score_list_faces_cars.append(score*100)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) evaluation intact faces vs rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_score_list = np.sort(score_list_if_rest)\n",
    "subject_ids = [i+1 for i in range(40)]\n",
    "subject_ids = [x for _, x in sorted(zip(score_list_if_rest, subject_ids), key=lambda pair: pair[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "ax2 = figure.add_subplot(111)\n",
    "ax2.plot(sorted_score_list[::-1], marker='o',linewidth=0, label='accuracy')\n",
    "ax2.plot(np.ones(shape=(len(sorted_score_list)))*50, color='black', alpha=0.75)\n",
    "plt.xticks(np.arange(40), subject_ids[::-1])\n",
    "ax2.set_title('Accuracy with Logistic-Regression for classes intact-faces / rest')\n",
    "ax2.set_xlabel('Subject IDs')\n",
    "ax2.set_ylabel('Accuracy in %')\n",
    "ax2.legend(loc=1)\n",
    "#plt.savefig('./analysis_images/accuracy_logistic_regression_intact_faces_rest')\n",
    "#plt.close(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array('decoding_data/score_intact_faces_rest_logreg.npy', score_list_if_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list_if_rest = load_array_from_memory('decoding_data/score_intact_faces_rest_logreg.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) evaluation all faces vs all cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_score_list_faces_cars = np.sort(score_list_faces_cars)\n",
    "subject_ids = [i+1 for i in range(40)]\n",
    "subject_ids = [x for _, x in sorted(zip(score_list_faces_cars, subject_ids), key=lambda pair: pair[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "ax2 = figure.add_subplot(111)\n",
    "ax2.plot(sorted_score_list_faces_cars[::-1], marker='o',linewidth=0, label='accuracy')\n",
    "ax2.plot(np.ones(shape=(len(sorted_score_list_faces_cars)))*50, color='black', alpha=0.75)\n",
    "plt.xticks(np.arange(40), subject_ids[::-1])\n",
    "ax2.set_title('Accuracy with Logistic-Regression for classes all-faces / all cars')\n",
    "ax2.set_xlabel('Subject IDs')\n",
    "ax2.set_ylabel('Accuracy in %')\n",
    "ax2.legend(loc=1)\n",
    "#plt.savefig('./analysis_images/accuracy_logistic_regression_all_faces_all_cars')\n",
    "#plt.close(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "ax2 = figure.add_subplot(111)\n",
    "ax2.plot(sorted_score_list_faces_cars[::-1], marker='o',linewidth=0, label='accuracy all faces/all cars')\n",
    "ax2.plot(sorted_score_list[::-1], marker='o',linewidth=0, label='accuracy intact faces/rest')\n",
    "ax2.plot(np.ones(shape=(len(sorted_score_list_faces_cars)))*50, color='black', alpha=0.75)\n",
    "ax2.plot(np.ones(shape=(len(sorted_score_list_faces_cars)))*75, color='black', alpha=0.75)\n",
    "plt.xticks(np.arange(40), np.arange(start=1, stop=41))\n",
    "ax2.set_title('Accuracy with Logistic-Regression')\n",
    "ax2.set_xlabel('Subjects')\n",
    "ax2.set_ylabel('Accuracy in %')\n",
    "ax2.legend(loc=1)\n",
    "#plt.savefig('./analysis_images/accuracy_logistic_regression_all_faces_all_cars')\n",
    "#plt.close(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_array('decoding_data/score_all_faces_all_cars_logreg.npy', sorted_score_list_faces_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_score_list_faces_cars = load_array_from_memory('decoding_data/score_all_faces_all_cars_logreg.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Doctests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_classes(array):\n",
    "    '''\n",
    "    >>> check_classes(y_faces_cars)\n",
    "    1\n",
    "    \n",
    "    >>> check_classes(y_intact_faces_rest)\n",
    "    1\n",
    "    \n",
    "    >>> check_classes(y_four_classes)\n",
    "    3\n",
    "    '''\n",
    "    return int(np.max(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_range_2D_array(to_check, min_value, max_value):\n",
    "    '''\n",
    "    >>> check_range_2D_array(score_list_if_rest[0], 0, 100)\n",
    "    True\n",
    "    \n",
    "    >>> check_range_2D_array(score_list_faces_cars[0], 0, 100)\n",
    "    True\n",
    "    '''\n",
    "    for x in to_check:\n",
    "        for y in x:\n",
    "            if y < min_value or y > max_value:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest\n",
    "doctest.testmod(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
